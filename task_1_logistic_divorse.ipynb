{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMHjtVPbyaKP"
   },
   "source": [
    "## Logistic Regression Model from scratch for Divorce Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJi26z8awmSD"
   },
   "source": [
    "### Logistic regression\n",
    "Logistic regression uses an equation as the representation, very much like linear regression.\n",
    "\n",
    "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a numeric value.<br>\n",
    "\n",
    "#####  $\\hat{y}$ (w, x) = 1/(1+exp^-(w_0 + w_1 * x_1 + ... + w_p * x_ps))\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at http://archive.ics.uci.edu/ml/machine-learning-databases/00520/data.zip. Unzip the file and use either CSV or xlsx file. Dataset is based on rating for questionnaire filled by people who already got divorse and those who is happily married.<br>\n",
    "\n",
    "#### Features (X)\n",
    "1. If one of us apologizes when our discussion deteriorates, the discussion ends.\n",
    "2. I know we can ignore our differences, even if things get hard sometimes.\n",
    "3. When we need it, we can take our discussions with my spouse from the beginning and correct it.\n",
    "4. When I discuss with my spouse, to contact him will eventually work.\n",
    "5. The time I spent with my wife is special for us.\n",
    "6. We don't have time at home as partners.\n",
    "7. We are like two strangers who share the same environment at home rather than family.\n",
    "8. I enjoy our holidays with my wife.\n",
    "9. I enjoy traveling with my wife.\n",
    "10. Most of our goals are common to my spouse.\n",
    "11. I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.\n",
    "12. My spouse and I have similar values in terms of personal freedom.\n",
    "13. My spouse and I have similar sense of entertainment.\n",
    "14. Most of our goals for people (children, friends, etc.) are the same.\n",
    "15. Our dreams with my spouse are similar and harmonious.\n",
    "16. We're compatible with my spouse about what love should be.\n",
    "17. We share the same views about being happy in our life with my spouse\n",
    "18. My spouse and I have similar ideas about how marriage should be\n",
    "19. My spouse and I have similar ideas about how roles should be in marriage\n",
    "20. My spouse and I have similar values in trust.\n",
    "21. I know exactly what my wife likes.\n",
    "22. I know how my spouse wants to be taken care of when she/he sick.\n",
    "23. I know my spouse's favorite food.\n",
    "24. I can tell you what kind of stress my spouse is facing in her/his life.\n",
    "25. I have knowledge of my spouse's inner world.\n",
    "26. I know my spouse's basic anxieties.\n",
    "27. I know what my spouse's current sources of stress are.\n",
    "28. I know my spouse's hopes and wishes.\n",
    "29. I know my spouse very well.\n",
    "30. I know my spouse's friends and their social relationships.\n",
    "31. I feel aggressive when I argue with my spouse.\n",
    "32. When discussing with my spouse, I usually use expressions such as ‘you always’ or ‘you never’ .\n",
    "33. I can use negative statements about my spouse's personality during our discussions.\n",
    "34. I can use offensive expressions during our discussions.\n",
    "35. I can insult my spouse during our discussions.\n",
    "36. I can be humiliating when we discussions.\n",
    "37. My discussion with my spouse is not calm.\n",
    "38. I hate my spouse's way of open a subject.\n",
    "39. Our discussions often occur suddenly.\n",
    "40. We're just starting a discussion before I know what's going on.\n",
    "41. When I talk to my spouse about something, my calm suddenly breaks.\n",
    "42. When I argue with my spouse, ı only go out and I don't say a word.\n",
    "43. I mostly stay silent to calm the environment a little bit.\n",
    "44. Sometimes I think it's good for me to leave home for a while.\n",
    "45. I'd rather stay silent than discuss with my spouse.\n",
    "46. Even if I'm right in the discussion, I stay silent to hurt my spouse.\n",
    "47. When I discuss with my spouse, I stay silent because I am afraid of not being able to control my anger.\n",
    "48. I feel right in our discussions.\n",
    "49. I have nothing to do with what I've been accused of.\n",
    "50. I'm not actually the one who's guilty about what I'm accused of.\n",
    "51. I'm not the one who's wrong about problems at home.\n",
    "52. I wouldn't hesitate to tell my spouse about her/his inadequacy.\n",
    "53. When I discuss, I remind my spouse of her/his inadequacy.\n",
    "54. I'm not afraid to tell my spouse about her/his incompetence.\n",
    "\n",
    "#### Target (y)\n",
    "55. Class: 1 - Divorsed, 0 - Not Divorsed (Yet) \n",
    "\n",
    "#### Objective\n",
    "To gain understanding of logistic regression through implementing the model from scratch\n",
    "\n",
    "#### Tasks\n",
    "- Download the data from above mentioned dataset link\n",
    "- Extract the zip file and use either CSV file or XLSX file (Note: CSV files contain semicolon ; as delimiter). Load the data and define X and y as numpy array\n",
    "- Add column at position 0 with all values=1 (pandas.DataFrame.insert function). This is for input to the bias W0.\n",
    "- Print the shape and datatype of both X and y\n",
    "- Dataset contains missing values, hence fill the missing values (NA) by performing missing value prediction.\n",
    "- Since the all the features are in higher range, columns can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique. Use Sklearn builtin functions from sklearn.preprocessing.\n",
    "- Split the dataset into 60% for training and rest 40% for testing. You can utilize built in function train_test_split in sklearn for this task. \n",
    "- Follow code cells to implement simple logistic regression from scratch\n",
    "    - Write hypothesis function to predict values\n",
    "    - Write function for calculating cross entropy loss (or log loss)\n",
    "    - Write function to return gradients for given weights\n",
    "    - Perform gradient descent taking help of above functions\n",
    "    - Write function for calculating accuracy\n",
    "- Train the model using training set using the function implementation\n",
    "- Predict the output for testing set samples and compute accuracy\n",
    "\n",
    "#### Further Fun (will not be evaluated)\n",
    "- Play with learning rate and max_iterations\n",
    "- Testing between whether label encoder vs one hot encoder for categorical features gives better results.\n",
    "- Running model with different feature scaling methods (i.e. scaling, normalization, standardization etc using sklearn)\n",
    "- Training model with different sizes of dataset splitting such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc.\n",
    "- Shuffling of training samples with different random seed values in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Write functions for other classification metrics such as confusion matrix,  precision, recall and f1 scores.\n",
    "\n",
    "\n",
    "#### Helpful links\n",
    "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
    "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21J6cpd_wmSE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4SL1fdNt1k3Q"
   },
   "outputs": [],
   "source": [
    "# Download the dataset from the source\n",
    "!wget URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1597993617875,
     "user": {
      "displayName": "Sridhar Swaminathan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvUjpWNY_tn9Efzip10QlZv44o7sSIu_Q4keU8=s64",
      "userId": "13395525706176391075"
     },
     "user_tz": -330
    },
    "id": "8VrbXJzI1l4Q"
   },
   "outputs": [],
   "source": [
    "# Unzip the file to the local cloud directory\n",
    "!unzip file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9av7W-wowmSI"
   },
   "outputs": [],
   "source": [
    "# Read the data from local cloud directory\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7zW8CA5wmSM"
   },
   "outputs": [],
   "source": [
    "# Add column which has all 1s\n",
    "# The idea is that weight corresponding to this column is equal to intercept\n",
    "# This way it is efficient and easier to handle the bias/intercept term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV1jGAQxwmSP"
   },
   "outputs": [],
   "source": [
    "# Print the dataframe rows to just see some samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joRU6dWxwmSR"
   },
   "outputs": [],
   "source": [
    "# Define X (input features) and y (output feature) \n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAyM-CYCwmSU"
   },
   "outputs": [],
   "source": [
    "X_shape = \n",
    "X_type  = \n",
    "y_shape = \n",
    "y_type  = \n",
    "print(f'X: Type-{X_type}, Shape-{X_shape}')\n",
    "print(f'y: Type-{y_type}, Shape-{y_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdLIVOm127-z"
   },
   "outputs": [],
   "source": [
    "# Perform missing value prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "En9Kb9dh2-wm"
   },
   "outputs": [],
   "source": [
    "# Perform feature scaling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8WF-EqO3BEa"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "X_train, X_test, y_train, y_test = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acCATJhI3FdH"
   },
   "outputs": [],
   "source": [
    "# Print the shape of features and target of training and testing: X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSa7cW-NwmSd"
   },
   "source": [
    "##### Let us start implementing logistic regression from scratch. Just follow code cells, see hints if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzle-PngwmSd"
   },
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    y_pred = \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert (y_pred.shape==(X.shape[0],)), 'Wrong implementation of predict function. Check carefully'\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5jkk7EywmSg"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_train, y_pred) : \n",
    "    '''\n",
    "    y_true : (m,1)\n",
    "    y_pred : (m,1)\n",
    "    \n",
    "    cross entropy loss (or log loss)\n",
    "    '''\n",
    "    ### START CODE HERE ###\n",
    "    loss = \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1WeTD0gwmSj"
   },
   "outputs": [],
   "source": [
    "def gradient(X_train, y_train, y_pred):\n",
    "\n",
    "    # Initialize the gradient vector \n",
    "    grad = np.zeros(,)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    grad[0] = \n",
    "    grad[1] = \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UcnO5tUnwmSl"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate=0.01, max_iterations=100):\n",
    "\n",
    "    # Initialise weights vector of random values\n",
    "    weights = np.random.rand()\n",
    "    # Initialize a list to record all the losses \n",
    "    losses  = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return weights, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifijezLg4eI_"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_test):\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    accuracy = \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C2Mn7wfKwmSo"
   },
   "source": [
    "##### Congratulations! You have implemented logistic regression from scratch. Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tvMc0OqwmSp"
   },
   "outputs": [],
   "source": [
    "# Perform gradient descent\n",
    "optimal_weights, losses = gradient_descent(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZQ8ITUt4b0N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7O5vUhHwmSr"
   },
   "outputs": [],
   "source": [
    "# Print final loss\n",
    "print(\"Cross Entropy loss:\", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrZ2wd_xwmSu"
   },
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i for i in range(len(losses))], losses)\n",
    "plt.title(\"Loss curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5b4bLDkwmSx"
   },
   "outputs": [],
   "source": [
    "# Make predictions for testing set using trained weights\n",
    "y_pred = hypothesis(X_test, optimal_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOfKSnz15TbF"
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy score for the testing set\n",
    "\n",
    "accuracy = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUt_zkDrwmS2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task_1_logistic_divorse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
